# to_do_features


FRAMEWORK:

- config for multiple local LLM's to be loaded.


	-> agentic framework: can you use deepseek's analysis and pass down the instrucions to local Qwen?
	-> can we use llama as a prompt instructor?

- config for API's (multiple models)

@deepseek -> using MCP


All models + API's can use MCP functionality.

Where are the system prompt located?

1 config file for everyhing

requirements.txt -> VENV

Cool startup screen



